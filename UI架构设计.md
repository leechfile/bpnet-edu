### UI架构设计

主界面包括三个按钮：

- 测试网络 自主创建网络并训练测试

- 实验教学 选择给定的数据进行测试

- 退出 退出软件界面

测试网络与实验教学相同

**展示数据**-->**导入数据**-->**开始训练**-->**训练结果可视化**

### 主界面

三个按钮,以及标题，使用Qt-Designer进行设计

**stylesheet**：设置stylesheet例如

`background-color:yellow `

`border-image:url(./images/python.jpg)`

使用`Qpixmap`来进行设置`background-repeat: no-repeat`来进行

### 测试/实验界面

#### 展示数据(实验)

展示数据,以及一个开始训练按钮。(教育目的)

要么也是选择一个数据进行上传。(测试网络)

#### 展示模型(测试)  / 构建模型(实验)

展示模型 , 展示设定模型的参数

构建模型--> 展示构建模型的参数 同时()

#### 展示细致的训练过程

- loss , accuracy 曲线 （在代码中进行修改，并且储存相应的loss,accuracy值）

- 网络权重图 (包含网络曲线)

#### 小功能

1.展现训练日志

2.实现一个preprocess 模块进行



### 反向传播

当你要训练一个神经网络，尤其是一个具有多层的神经网络时，反向传播是一个关键的步骤，用于调整网络的权重和偏差以最小化损失函数。我将描述一个简单的示例，其中有一个包含2100个样本的输入数据集，一个2x4x3的神经网络结构，并且涉及到反向传播的过程。

首先，让我们定义一些符号：

- 输入数据集：X，维度为2100x2，其中每一行代表一个样本，每一列代表一个特征。
- 神经网络的结构：2x4x3，包括输入层（2个神经元），隐藏层（4个神经元）和输出层（3个神经元）。
- 权重矩阵：W，包括两个权重矩阵W1（连接输入层和隐藏层）和W2（连接隐藏层和输出层）。
- 偏差向量：b，包括两个偏差向量b1（对应隐藏层）和b2（对应输出层）。
- 激活函数：σ，通常是Sigmoid、ReLU等。
- 损失函数：L，通常是均方误差（MSE）或交叉熵损失。

反向传播的过程可以分为以下几个步骤：

1. **前向传播**：
   
   - 计算输入层到隐藏层的加权输入：$Z1 = X \cdot W1 + b1$，其中$Z1$是一个2100x4的矩阵。
   - 应用激活函数：$A1 = \sigma(Z1)$。
   - 计算隐藏层到输出层的加权输入：$Z2 = A1 \cdot W2 + b2$，其中$Z2$是一个2100x3的矩阵。
   - 再次应用激活函数：$A2 = \sigma(Z2)$。

2. **计算损失**：
   
   - 使用损失函数计算网络的整体损失：$L = \frac{1}{2100}\sum_{i=1}^{2100} L_i$，其中$L_i$是单个样本的损失。

3. **反向传播**：
   
   - 计算输出层的误差：$dL/dZ2$，根据损失函数的不同，误差计算方式也不同。例如，对于MSE损失，$dL/dZ2 = (A2 - Y)$，其中Y是实际的目标输出。
   - 使用链式法则计算隐藏层的误差：$dL/dZ1 = (dL/dZ2) \cdot (W2^T) \cdot (A1 \cdot (1 - A1))$。
   - 计算权重和偏差的梯度：
     - $dW2 = (A1^T \cdot (dL/dZ2)) / 2100$
     - $db2 = \sum(dL/dZ2) / 2100$
     - $dW1 = (X^T \cdot (dL/dZ1)) / 2100$
     - $db1 = \sum(dL/dZ1) / 2100$

4. **权重和偏差更新**：
   
   - 使用梯度下降或其他优化算法来更新权重和偏差：
     - $W2 = W2 - learning\_rate \cdot dW2$
     - $b2 = b2 - learning\_rate \cdot db2$
     - $W1 = W1 - learning\_rate \cdot dW1$
     - $b1 = b1 - learning\_rate \cdot db1$

5. **重复**：
   
   - 重复上述步骤多次，直到损失函数收敛或达到预定的训练迭代次数。这个过程将反复进行，每次迭代都会调整权重和偏差，以使网络的预测逐渐接近目标值，直到训练完成。需要注意的是，这只是一个简化的示例，实际中可能还涉及到正则化、批量处理、学习率调整等技巧，以提高训练的效果。

-等到开始训练的时候-->又出现了问题无法进行训练，陷入了死循环





#### error list

有错误,**self.listweight[i] - = lr * dcost_wo**

没有办法进行广播 np.dot() 

[7 4 1]   ==》 4x1 进行广播

6x8维度的数据

6x7 

value - target 

我们需要弄清楚前面几个维度的变化

soft
